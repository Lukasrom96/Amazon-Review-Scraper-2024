{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwEezB5kD0zX"
      },
      "source": [
        "# **AMAZON REVIEW SCRAPER 2024**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Beschreibung:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dieses Skript umfasst einen Amazon-Review-Webscraper, welcher die Limitationen von Amazon (nur 100 sichtbare Rezensionen pro Produkt) durch Anwendung verschiedener Filter umgeht. So ist es Möglich bis zu 1500 Produktrezensionen pro Produktvariation (z.B. Größe) zu scrapen. Die Informationen: \n",
        "1. Kundenname\n",
        "2. Reviewtitel\n",
        "3. Herkunftsland\n",
        "4. Datum\n",
        "5. Produktvariation\n",
        "6. Review-Text\n",
        "7. Sternebewertung\n",
        "8. Anzahl der Likes\n",
        "\n",
        "werden bei der Ausführung einzeln extrahiert und in eine CSV-Datei eingetragen, um nach dem Scraping Prozess weiter verwendet werden zu können.\n",
        "\n",
        "Um das Skript nutzen zu können sind einige Voraussetzungen notwendig. Im Folgenden wird eine vollständige Anleitung gegeben.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS6DbSQcD0zY"
      },
      "source": [
        "## Voraussetzungen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_gdbAXUD0zY",
        "outputId": "e0eeab4a-5781-48b2-b114-213c497f1fbc"
      },
      "outputs": [],
      "source": [
        "# ZU BEGINN: Lade notwendige Packages\n",
        "# pip install pandas\n",
        "# pip install beautifulsoup4\n",
        "# pip install selenium\n",
        "\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CA3AS7xPD0zZ"
      },
      "outputs": [],
      "source": [
        "# Selenium benutzt einen Webdriver!\n",
        "# Dieser muss vorher heruntergeladen werden!\n",
        "\n",
        "# ANLEITUNG:\n",
        "\n",
        "# 1. Downloade kompatiblen Driver\n",
        "\n",
        "#Chrome:  https://chromedriver.chromium.org\n",
        "#Firefox: https://github.com/mozilla/geckodriver/releases\n",
        "#Safari:  https://webkit.org/blog/6900/webdriver-support-in-safari-10/\n",
        "\n",
        "# 2. Extrahiere den Webdriver aus der Zip-Datei und speichere den Webdriver unter:\n",
        "# WINDOWS:  C:\\Windows\\System32 \n",
        "# MAC: usr/local/bin \n",
        "\n",
        "# FERTIG!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7pA6sjHqD0zZ"
      },
      "outputs": [],
      "source": [
        "# Um auf Mehrere Rezensionsseiten eines Produktes zugreifen zu können, wird ein Amazon-Account benötigt:\n",
        "\n",
        "# Wenn nicht der Privataccount genutzt werden soll:\n",
        "\n",
        "#1. Anonyme Email-Adresse erstellen unter: https://tuta.com/de/\n",
        "\n",
        "#2. Amazon Account mit anonymer Email-Adresse erstellen unter: https://www.amazon.de/ap/register?openid.mode=checkid_setup&openid.ns=http%3A%2F%2Fspecs.openid.net%2Fauth%2F2.0&openid.return_to=https%3A%2F%2Fwww.amazon.de%2Fref%3Drhf_sign_in&openid.assoc_handle=deflex\n",
        "\n",
        "\n",
        "# Benutzerdaten eingeben\n",
        "email = \"MaxMustermann@tutamail.com\"\n",
        "password = \"passwort\"\n",
        "\n",
        "# URL des Produktes Eingeben (von dem die Rezensionen verlangt werden)\n",
        "url = 'https://www.amazon.de/Bonsai-Starter-Kit-Bonsai-Anzuchtset-wundersch%C3%B6nen/dp/B08BTZK7CT/ref=sr_1_2_sspa?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=2N60HUUWW0MQM&dib=eyJ2IjoiMSJ9.N3FS1MXb-D1UIuWY5nEt9FfyMB-9NMrcIHlkdQg9L-Wqk3029rUW-1oDPXeLtfQJPXSaRSMeBfcZ73nNs5ONVhwIqhc08rniHoxI_uRQq5uscIsQMPfV25R54overiMNK4wmo3Mw7a2MuJcx-sSxCLjPQNVLbUP8B4ipgpLHsVima73jlSX6htxuWuKUw1I2NH5_EbLYknX3-0L6x9dcsbPEMcJobKS-tQB7GldTqmANKPud5dYCGj8vhCsK_2tm5cNEptv0GVjicmwa6tPpUaH1vltgIRWg0zkp5mc5SIo.OisVgWYO63WeWeq8OCGQ0Sh062UuTBxaQuMU8Hma3Ko&dib_tag=se&keywords=bonsai&qid=1712178520&sprefix=bonsai%2Caps%2C93&sr=8-2-spons&sp_csd=d2lkZ2V0TmFtZT1zcF9hdGY&th=1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFyKe_Z1D0za"
      },
      "source": [
        "## Funktionen und Definition der Filterkriterien"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ffGBhW9YD0za"
      },
      "outputs": [],
      "source": [
        "# SCRAPING FUNKTION (immer für eine aufgerufene Seite)\n",
        "\n",
        "def ama_scrape(soup):\n",
        "    reviews = []\n",
        "    # Finde alle Reviews auf der Seite\n",
        "    for review in soup.findAll('div', class_='review'):\n",
        "        # Extrahiere User-Name\n",
        "        name_user = review.find('span', class_='a-profile-name').text.strip()\n",
        "        # Extrahiere Titel des Reviews\n",
        "        if review.find('span',class_='').text.strip() == 'Melden':  # Falls kein Titel vorhanden ist, wird der nächste <span> genommen -> verhindert\n",
        "            titel = ''\n",
        "        else:\n",
        "            titel = review.find('span',class_='').text.strip()\n",
        "        # Extrahiere Datum und Land\n",
        "        datum_land = review.find('span', class_= 'a-size-base a-color-secondary review-date').text.strip()\n",
        "        if len(datum_land.split(' vom ',1)) == 2:\n",
        "            land, datum = datum_land.split(' vom ',1)\n",
        "            land = land.split()[-1]\n",
        "        else:\n",
        "            land = ''\n",
        "            datum = ''\n",
        "        # Extrahiere die Produktausprägung\n",
        "        variation = review.find('a', attrs={'data-hook':'format-strip'})\n",
        "        if variation and variation.text:\n",
        "            variation = review.find('a', attrs={'data-hook':'format-strip'}).text.strip()\n",
        "        else:\n",
        "            variation = ''\n",
        "        # Extrahiere den Review Text\n",
        "        text = review.find('span', class_='review-text').text.strip()\n",
        "        # Extrahiere die Sterne-Bewertung\n",
        "        stars = review.find('i', class_='review-rating').text.strip()[0]\n",
        "        # Extrahiere die 'Hilfreich'-Angaben\n",
        "        hilfreich = review.find('span', class_='a-size-base a-color-tertiary cr-vote-text')\n",
        "        if hilfreich and hilfreich.text:\n",
        "            hilfreich = review.find('span', class_='a-size-base a-color-tertiary cr-vote-text').text.strip().split()[0]\n",
        "            if hilfreich == 'Eine':\n",
        "                hilfreich = 1\n",
        "        else:\n",
        "            hilfreich = '0'\n",
        "\n",
        "        # Review-Daten in Liste speichern\n",
        "        reviews.append({\n",
        "            'Name' : name_user,\n",
        "            'Titel': titel,\n",
        "            'Land': land,\n",
        "            'Datum': datum,\n",
        "            'Variation': variation,\n",
        "            'Text': text,\n",
        "            'Sterne': stars,\n",
        "            'Hilfreich': hilfreich\n",
        "        })\n",
        "\n",
        "    # DataFrame aus der Liste erstellen\n",
        "    df = pd.DataFrame(reviews)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MtbIYhrJD0za"
      },
      "outputs": [],
      "source": [
        "# Dataframe zum sammeln der Reviews\n",
        "complete_reviews = pd.DataFrame()\n",
        "\n",
        "# FILTERREGISTER (Filtert später die Rezensionen -> Für jedes Produkt gleich!)\n",
        "# Kann bei Aktualisierungen Seiten Amazons angepasst werden.\n",
        "\n",
        "# neueste,verifiziert,alle sterne,alle formate\n",
        "filter_1 ='ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1'\n",
        "# neueste,verifiziert,kritische,alle formate\n",
        "filter_2 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=critical'\n",
        "# neueste,verifiziert,positive,alle formate\n",
        "filter_3 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=positive'\n",
        "# neueste,verifiziert,1 stern,alle formate\n",
        "filter_4 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=one_star'\n",
        "# neueste,verifiziert,2 sterne,alle formate\n",
        "filter_5 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=two_star'\n",
        "# neueste,verifiziert,3 sterne,alle formate\n",
        "filter_6 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=three_star'\n",
        "# neueste,verifiziert,4 sterne,alle formate\n",
        "filter_7 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=four_star'\n",
        "# neueste,verifiziert,5 sterne,alle formate\n",
        "filter_8 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1&filterByStar=five_star'\n",
        "# spitzen,verifiziert,kritisch,alle formate\n",
        "filter_9 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=critical'\n",
        "# spitzen,verifiziert,positiv,alle formate\n",
        "filter_10 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=positive'\n",
        "# spitzen,verifiziert,1 Stern,alle formate\n",
        "filter_11 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=one_star'\n",
        "# spitzen,verifiziert,2 Sterne,alle formate\n",
        "filter_12 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=two_star'\n",
        "# spitzen,verifiziert,3 Sterne,alle formate\n",
        "filter_13 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=three_star'\n",
        "# spitzen,verifiziert,4 Sterne,alle formate\n",
        "filter_14 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=four_star'\n",
        "# spitzen,verifiziert,5 Sterne,alle formate\n",
        "filter_15 = 'ref=cm_cr_arp_d_viewopt_sr?ie=UTF8&reviewerType=avp_only_reviews&sortBy=helpful&pageNumber=1&filterByStar=five_star'\n",
        "\n",
        "# LISTE ALLER FILTER\n",
        "all_filters = [filter_1,filter_2,filter_3,filter_4,filter_5,filter_6,filter_7,filter_8,filter_9,filter_10,filter_11,filter_12,filter_13,filter_14,filter_15,]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FK3lnA3GD0zb"
      },
      "outputs": [],
      "source": [
        "# FUNKTION ZUR ANWENDUNG ALLER FILTER\n",
        "def ama_scrape_with_filters(reviews_url,filters):\n",
        "\n",
        "    # URL aufspalten um Filter anzuwenden\n",
        "    base_url= reviews_url.split('/ref=')[0]\n",
        "\n",
        "    # Dataframe um Reviews innerhalb der Funktion zu speichern\n",
        "    all_reviews = pd.DataFrame()\n",
        "\n",
        "    for filter in all_filters:\n",
        "\n",
        "        #Link nach Filter anpassen\n",
        "        current_url = base_url + '/' + filter\n",
        "\n",
        "        # Scaping aller Seiten für eine Filteroption\n",
        "        for page in range(1,11): # Amazon stellt immer nur 10 Seiten zur Einsicht\n",
        "            if page == 1:\n",
        "                driver.get(current_url)\n",
        "                html = driver.page_source\n",
        "                soup = BeautifulSoup(html, \"html.parser\")\n",
        "                current_reviews = ama_scrape(soup)\n",
        "            else:\n",
        "                # Abfage ob es eine weitere Seite gibt\n",
        "                if (soup.find('li', class_='a-last') == None) or (soup.find('li', class_='a-last').find('a') == None):\n",
        "                    break\n",
        "                # Wenn es eine weitere Seite gibt\n",
        "                new_current_url = base_url + soup.find('li', class_='a-last').find('a')['href']\n",
        "                driver.get(new_current_url)\n",
        "                html = driver.page_source\n",
        "                soup = BeautifulSoup(html, \"html.parser\")\n",
        "                current_reviews = ama_scrape(soup)\n",
        "\n",
        "            # Reviews in Dataframe schreiben\n",
        "            all_reviews = pd.concat([all_reviews, current_reviews], ignore_index=True)\n",
        "\n",
        "    return all_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShxeSckvD0zc"
      },
      "source": [
        "## Scraping Prozess Step by Step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "USPfk9j1D0zc",
        "outputId": "8c9f3007-44c3-4130-ef11-ae797cd20b4f"
      },
      "outputs": [],
      "source": [
        "# EINLOGGEN UND AUF REZENSIONSSEITE GEHEN\n",
        "\n",
        "# Initialisierung des Webdrivers\n",
        "driver = webdriver.Firefox() # Alternativ webdriver.Chrome(), wenn WebDriver nicht unter C:\\Windows\\System32 gespeichert ist Pfad angeben! ->webdriver.Chrome('Pfad')\n",
        "driver.get(url)\n",
        "\n",
        "# Funktion um zu warten, bis die Seite geladen ist\n",
        "wait = WebDriverWait(driver, 10)\n",
        "\n",
        "# Ausgangspunkt: PRODUKTSEITE\n",
        "\n",
        "# Auf Sign-in Seite gehen\n",
        "sign_in_field = wait.until(EC.visibility_of_element_located((By.ID,\"nav-link-accountList\")))\n",
        "sign_in_field.click()\n",
        "\n",
        "# E-Mail eingeben und auf \"Weiter\" klicken\n",
        "email_field = wait.until(EC.visibility_of_element_located((By.ID, \"ap_email\")))\n",
        "email_field.send_keys(email)\n",
        "\n",
        "continue_button = wait.until(EC.element_to_be_clickable((By.ID, \"continue\")))\n",
        "continue_button.click()\n",
        "\n",
        "# Passwort eingeben und auf \"Anmelden\" klicken (Dauert idR. einige Sekunden)\n",
        "password_field = wait.until(EC.visibility_of_element_located((By.ID, \"ap_password\")))\n",
        "password_field.send_keys(password)\n",
        "\n",
        "sign_in_button = wait.until(EC.element_to_be_clickable((By.ID, \"signInSubmit\")))\n",
        "sign_in_button.click()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "skhna7zaD0zd"
      },
      "outputs": [],
      "source": [
        "# Übergang zu Rezensionsseite\n",
        "\n",
        "# WICHTIG:\n",
        "# Wenn eine bestimmte Variation des Produktes (Größe etc.) betrachtet werden soll -> im Webdriver anklicken\n",
        "# Wenn mehrere Variationen betrachtet werden sollen, müssen folgende Schritte Mehrfach durchgeführt werden -> Später im Skript\n",
        "\n",
        "# Link zur Rezensionsseite finden\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "reviews_url = 'https://www.amazon.de' + soup.findAll('a', class_='a-link-emphasis a-text-bold')[0]['href']\n",
        "driver.get(reviews_url)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ss5AvSWZD0zd"
      },
      "outputs": [],
      "source": [
        "# Alle verfügbaren Reviews aller Seiten und aller relevanten Filter scrapen\n",
        "current_variation_reviews = ama_scrape_with_filters(reviews_url, all_filters)\n",
        "\n",
        "# Falls weitere Produktvariationen abgefragt werden sollen -> In Sammeldataframe speichern\n",
        "complete_reviews = pd.concat([complete_reviews, current_variation_reviews], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVQsiHacD0zd"
      },
      "source": [
        "---------------------- Dieser Schritt ist beliebig oft wiederholbar------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqnuCwfgD0zd"
      },
      "outputs": [],
      "source": [
        "# Falls weitere Produktvariationen gescraped werden sollen:\n",
        "\n",
        "# Zur Produktseite zurückkehren\n",
        "driver.get(url)\n",
        "\n",
        "# !!!Nun bitte gewünschte Variation manuell anklicken!!!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX-m_QFLD0ze"
      },
      "outputs": [],
      "source": [
        "# Link zur Rezensionsseite finden\n",
        "html = driver.page_source\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "reviews_url = 'https://www.amazon.de' + soup.findAll('a', class_='a-link-emphasis a-text-bold')[0]['href']\n",
        "driver.get(reviews_url)\n",
        "\n",
        "# Alle verfügbaren Reviews aller Seiten und aller relevanten Filter scrapen\n",
        "current_variation_reviews = ama_scrape_with_filters(reviews_url, all_filters)\n",
        "\n",
        "# Falls weitere Produktvariationen abgefragt werden sollen -> In Sammeldataframe speichern\n",
        "complete_reviews = pd.concat([complete_reviews, current_variation_reviews], ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI1K9Jz1D0ze"
      },
      "source": [
        "---------------------- Ende der Iteration------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kxHSgM7ND0ze",
        "outputId": "b83293fa-d5bd-4352-fa96-8ed22503da11"
      },
      "outputs": [],
      "source": [
        "# Alle gewünschten Reviews beisammen? Wenn ja:\n",
        "\n",
        "# Abschließend Duplikate entfernen\n",
        "reviews_cleaned = complete_reviews.drop_duplicates()\n",
        "\n",
        "#Reviews in CSV-Datei speichern\n",
        "reviews_cleaned.to_csv('amazon_reviews.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "# Webdriver schließen\n",
        "driver.quit()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
